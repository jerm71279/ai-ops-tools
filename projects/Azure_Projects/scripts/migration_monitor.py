"""
OberaConnect Azure Migration Monitor
Aligned with OberaAI Strategy - Autonomous Back Office + 98/2 Principle

Feedback Loops for Azure Operations:
1. Robocopy Verification Loop - Parse logs, verify completeness, alert on failures
2. Azure Disk Clone Monitor - Track provisioning, measure actual vs estimated time
3. Permission Validation Loop - Test access post-migration, compare permissions
4. Performance Benchmark Loop - Record metrics to improve future estimates

Principle: AI handles 98% of routine monitoring, humans handle 2% exceptions
"""

import json
import re
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
import subprocess


class OperationStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    REQUIRES_REVIEW = "requires_review"


class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class MigrationOperation:
    """Track a migration operation"""
    id: str
    operation_type: str  # robocopy, disk_clone, permission_sync
    customer_id: str
    customer_name: str
    source: str
    destination: str
    status: OperationStatus
    started_at: str
    estimated_duration_minutes: int = 0
    actual_duration_minutes: int = 0
    completed_at: Optional[str] = None
    metrics: Dict[str, Any] = field(default_factory=dict)
    alerts: List[Dict] = field(default_factory=list)
    verified: bool = False
    verification_result: Optional[Dict] = None

    def to_dict(self) -> Dict:
        data = asdict(self)
        data['status'] = self.status.value
        return data


@dataclass
class Alert:
    """Alert generated by monitoring"""
    id: str
    operation_id: str
    severity: AlertSeverity
    message: str
    timestamp: str
    acknowledged: bool = False
    auto_resolved: bool = False
    requires_human: bool = False
    resolution_notes: Optional[str] = None

    def to_dict(self) -> Dict:
        data = asdict(self)
        data['severity'] = self.severity.value
        return data


class RobocopyVerificationLoop:
    """
    FEEDBACK LOOP 1: Robocopy Verification

    Monitors robocopy operations to:
    - Parse log files in real-time
    - Track file/folder counts
    - Detect failures and errors
    - Verify completion
    - Alert on issues (98/2 - only escalate real problems)
    """

    # Patterns for parsing robocopy output
    PATTERNS = {
        'dirs': r'Dirs\s*:\s*(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)',
        'files': r'Files\s*:\s*(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)',
        'bytes': r'Bytes\s*:\s*([\d.]+\s*[a-zA-Z]*)\s+([\d.]+\s*[a-zA-Z]*)',
        'times': r'Times\s*:\s*(\d+:\d+:\d+)',
        'speed': r'Speed\s*:\s*([\d,]+)\s*Bytes/sec',
        'error': r'ERROR\s+(\d+)\s+\(0x[0-9A-Fa-f]+\)\s+(.*)',
        'failed': r'(\d+)\s+FAILED',
    }

    # Known ignorable errors (98% automation)
    IGNORABLE_ERRORS = [
        'System Volume Information',
        'pagefile.sys',
        'hiberfil.sys',
        'swapfile.sys',
        'NTUSER.DAT',
        'ntuser.dat.LOG',
        'UsrClass.dat',
    ]

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.logs_dir = data_dir / "logs" / "robocopy"
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        self.operations_file = data_dir / "robocopy_operations.json"
        self._ensure_file()

    def _ensure_file(self):
        if not self.operations_file.exists():
            with open(self.operations_file, 'w') as f:
                json.dump({
                    'operations': {},
                    'benchmarks': {
                        'avg_speed_bytes_sec': 0,
                        'avg_files_per_minute': 0,
                        'total_operations': 0,
                        'success_rate': 0
                    },
                    'alerts': []
                }, f)

    def start_operation(
        self,
        customer_id: str,
        customer_name: str,
        source: str,
        destination: str,
        estimated_size_gb: float = 0
    ) -> str:
        """Start tracking a new robocopy operation"""

        operation_id = f"rc_{datetime.now().strftime('%Y%m%d%H%M%S')}_{customer_id[:8]}"

        # Estimate duration based on historical data
        estimated_minutes = self._estimate_duration(estimated_size_gb)

        operation = MigrationOperation(
            id=operation_id,
            operation_type='robocopy',
            customer_id=customer_id,
            customer_name=customer_name,
            source=source,
            destination=destination,
            status=OperationStatus.IN_PROGRESS,
            started_at=datetime.now().isoformat(),
            estimated_duration_minutes=estimated_minutes,
            metrics={
                'estimated_size_gb': estimated_size_gb,
                'files_copied': 0,
                'files_failed': 0,
                'dirs_copied': 0,
                'bytes_copied': 0
            }
        )

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        data['operations'][operation_id] = operation.to_dict()

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

        return operation_id

    def _estimate_duration(self, size_gb: float) -> int:
        """Estimate duration based on historical benchmarks"""
        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        avg_speed = data['benchmarks'].get('avg_speed_bytes_sec', 50_000_000)  # Default 50MB/s

        if avg_speed > 0:
            bytes_to_copy = size_gb * 1024 * 1024 * 1024
            seconds = bytes_to_copy / avg_speed
            return int(seconds / 60) + 30  # Add 30 min buffer
        else:
            return int(size_gb * 10)  # Rough estimate: 10 min per GB

    def parse_log(self, operation_id: str, log_content: str) -> Dict[str, Any]:
        """
        Parse robocopy log and update operation status

        Implements 98/2:
        - Automatically handles known errors
        - Only escalates genuine failures
        """

        result = {
            'parsed': True,
            'metrics': {},
            'errors': [],
            'warnings': [],
            'requires_human': False
        }

        # Parse directory stats
        dirs_match = re.search(self.PATTERNS['dirs'], log_content)
        if dirs_match:
            result['metrics']['dirs'] = {
                'total': int(dirs_match.group(1)),
                'copied': int(dirs_match.group(2)),
                'skipped': int(dirs_match.group(3)),
                'mismatch': int(dirs_match.group(4)),
                'failed': int(dirs_match.group(5)),
                'extras': int(dirs_match.group(6))
            }

        # Parse file stats
        files_match = re.search(self.PATTERNS['files'], log_content)
        if files_match:
            result['metrics']['files'] = {
                'total': int(files_match.group(1)),
                'copied': int(files_match.group(2)),
                'skipped': int(files_match.group(3)),
                'mismatch': int(files_match.group(4)),
                'failed': int(files_match.group(5)),
                'extras': int(files_match.group(6))
            }

        # Parse speed
        speed_match = re.search(self.PATTERNS['speed'], log_content)
        if speed_match:
            speed_str = speed_match.group(1).replace(',', '')
            result['metrics']['speed_bytes_sec'] = int(speed_str)

        # Parse errors
        for error_match in re.finditer(self.PATTERNS['error'], log_content):
            error_code = error_match.group(1)
            error_msg = error_match.group(2)

            # Check if error is ignorable (98% automation)
            is_ignorable = any(ignorable in error_msg for ignorable in self.IGNORABLE_ERRORS)

            if is_ignorable:
                result['warnings'].append({
                    'code': error_code,
                    'message': error_msg,
                    'status': 'auto_ignored',
                    'reason': 'Known system file - expected behavior'
                })
            else:
                result['errors'].append({
                    'code': error_code,
                    'message': error_msg,
                    'status': 'requires_review'
                })
                result['requires_human'] = True  # 2% human review

        # Check for failed files
        failed_match = re.search(self.PATTERNS['failed'], log_content)
        if failed_match:
            failed_count = int(failed_match.group(1))
            if failed_count > 0:
                result['metrics']['failed_count'] = failed_count

                # Determine if failures are acceptable
                if result['metrics'].get('files', {}).get('total', 0) > 0:
                    failure_rate = failed_count / result['metrics']['files']['total']
                    if failure_rate > 0.01:  # More than 1% failure
                        result['requires_human'] = True
                        result['errors'].append({
                            'type': 'high_failure_rate',
                            'rate': f"{failure_rate:.2%}",
                            'count': failed_count
                        })

        # Update operation
        self._update_operation(operation_id, result)

        return result

    def _update_operation(self, operation_id: str, parse_result: Dict) -> None:
        """Update operation with parsed results"""

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        if operation_id not in data['operations']:
            return

        op = data['operations'][operation_id]
        op['metrics'].update(parse_result['metrics'])

        if parse_result['requires_human']:
            op['status'] = OperationStatus.REQUIRES_REVIEW.value
            # Create alert
            alert = {
                'id': f"alert_{operation_id}_{datetime.now().strftime('%H%M%S')}",
                'operation_id': operation_id,
                'severity': 'warning',
                'message': f"Robocopy operation requires review: {len(parse_result['errors'])} errors",
                'timestamp': datetime.now().isoformat(),
                'errors': parse_result['errors']
            }
            data['alerts'].append(alert)
            op['alerts'].append(alert)
        elif parse_result['errors']:
            op['status'] = OperationStatus.REQUIRES_REVIEW.value
        else:
            # Check if complete
            files_metrics = parse_result['metrics'].get('files', {})
            if files_metrics.get('total', 0) > 0:
                if files_metrics.get('failed', 0) == 0:
                    op['status'] = OperationStatus.COMPLETED.value
                    op['completed_at'] = datetime.now().isoformat()

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

    def verify_completion(self, operation_id: str) -> Dict[str, Any]:
        """
        FEEDBACK LOOP: Verify robocopy completion

        Compares source and destination to ensure completeness
        """

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        if operation_id not in data['operations']:
            return {'error': 'Operation not found'}

        op = data['operations'][operation_id]

        verification = {
            'operation_id': operation_id,
            'verified_at': datetime.now().isoformat(),
            'checks': [],
            'passed': True
        }

        # Check 1: Files copied vs total
        files = op['metrics'].get('files', {})
        if files:
            copied = files.get('copied', 0) + files.get('skipped', 0)
            total = files.get('total', 0)
            files_check = {
                'check': 'file_count',
                'expected': total,
                'actual': copied,
                'passed': copied >= total * 0.99  # 99% threshold
            }
            verification['checks'].append(files_check)
            if not files_check['passed']:
                verification['passed'] = False

        # Check 2: No critical failures
        failed = files.get('failed', 0)
        failure_check = {
            'check': 'failure_count',
            'failed': failed,
            'passed': failed == 0
        }
        verification['checks'].append(failure_check)
        if failed > 0:
            # Check if all failures are ignorable
            # This would require re-parsing the log
            pass

        # Check 3: Duration within estimate
        if op.get('completed_at') and op.get('started_at'):
            started = datetime.fromisoformat(op['started_at'])
            completed = datetime.fromisoformat(op['completed_at'])
            actual_minutes = (completed - started).total_seconds() / 60

            op['actual_duration_minutes'] = int(actual_minutes)

            duration_check = {
                'check': 'duration',
                'estimated_minutes': op['estimated_duration_minutes'],
                'actual_minutes': int(actual_minutes),
                'within_estimate': actual_minutes <= op['estimated_duration_minutes'] * 1.5
            }
            verification['checks'].append(duration_check)

        # Update operation with verification
        op['verified'] = verification['passed']
        op['verification_result'] = verification

        # Update benchmarks if successful
        if verification['passed']:
            self._update_benchmarks(op)

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

        return verification

    def _update_benchmarks(self, operation: Dict) -> None:
        """
        FEEDBACK LOOP: Performance Benchmark

        Learn from completed operations to improve estimates
        """

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        benchmarks = data['benchmarks']

        # Update speed average
        speed = operation['metrics'].get('speed_bytes_sec', 0)
        if speed > 0:
            total_ops = benchmarks['total_operations']
            current_avg = benchmarks['avg_speed_bytes_sec']
            new_avg = ((current_avg * total_ops) + speed) / (total_ops + 1)
            benchmarks['avg_speed_bytes_sec'] = int(new_avg)

        # Update operation count
        benchmarks['total_operations'] += 1

        # Update success rate
        successful = sum(1 for op in data['operations'].values()
                        if op.get('status') == 'completed' and op.get('verified', False))
        benchmarks['success_rate'] = successful / max(benchmarks['total_operations'], 1)

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

    def get_operation_status(self, operation_id: str) -> Dict[str, Any]:
        """Get current status of an operation"""

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        return data['operations'].get(operation_id, {'error': 'Not found'})

    def get_pending_alerts(self) -> List[Dict]:
        """Get all unacknowledged alerts requiring human review"""

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        return [a for a in data['alerts'] if not a.get('acknowledged', False)]


class AzureDiskCloneLoop:
    """
    FEEDBACK LOOP 2: Azure Disk Clone Monitor

    Monitors Azure disk cloning operations to:
    - Track provisioning state
    - Measure actual vs estimated duration
    - Alert on failures or timeouts
    - Build duration estimates from history
    """

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.operations_file = data_dir / "disk_clone_operations.json"
        self._ensure_file()

    def _ensure_file(self):
        if not self.operations_file.exists():
            with open(self.operations_file, 'w') as f:
                json.dump({
                    'operations': {},
                    'benchmarks': {
                        'by_sku': {},
                        'by_size_gb': {},
                        'avg_duration_minutes': 45
                    },
                    'alerts': []
                }, f)

    def start_clone(
        self,
        customer_id: str,
        customer_name: str,
        source_disk: str,
        target_disk: str,
        disk_size_gb: int,
        sku: str = 'Premium_LRS'
    ) -> str:
        """Start tracking a disk clone operation"""

        operation_id = f"clone_{datetime.now().strftime('%Y%m%d%H%M%S')}_{customer_id[:8]}"

        # Estimate based on historical data
        estimated_minutes = self._estimate_duration(disk_size_gb, sku)

        operation = MigrationOperation(
            id=operation_id,
            operation_type='disk_clone',
            customer_id=customer_id,
            customer_name=customer_name,
            source=source_disk,
            destination=target_disk,
            status=OperationStatus.IN_PROGRESS,
            started_at=datetime.now().isoformat(),
            estimated_duration_minutes=estimated_minutes,
            metrics={
                'disk_size_gb': disk_size_gb,
                'sku': sku,
                'provisioning_state': 'Creating',
                'progress_checks': []
            }
        )

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        data['operations'][operation_id] = operation.to_dict()

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

        return operation_id

    def _estimate_duration(self, size_gb: int, sku: str) -> int:
        """Estimate clone duration based on historical data"""

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        benchmarks = data['benchmarks']

        # Check SKU-specific benchmark
        if sku in benchmarks['by_sku']:
            sku_data = benchmarks['by_sku'][sku]
            if sku_data.get('count', 0) > 0:
                base_time = sku_data['avg_minutes']
                # Scale by size
                size_factor = size_gb / sku_data.get('avg_size_gb', 500)
                return int(base_time * max(1, size_factor))

        # Default estimates by SKU
        sku_defaults = {
            'Premium_LRS': 30,
            'StandardSSD_LRS': 45,
            'Standard_LRS': 60
        }

        base = sku_defaults.get(sku, 45)
        # Add time for larger disks
        size_factor = max(1, size_gb / 500)
        return int(base * size_factor)

    def check_status(self, operation_id: str, provisioning_state: str) -> Dict[str, Any]:
        """
        Update operation with current Azure provisioning state

        Called periodically during clone operation
        """

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        if operation_id not in data['operations']:
            return {'error': 'Operation not found'}

        op = data['operations'][operation_id]

        # Record progress check
        check = {
            'timestamp': datetime.now().isoformat(),
            'state': provisioning_state
        }
        op['metrics']['progress_checks'].append(check)
        op['metrics']['provisioning_state'] = provisioning_state

        result = {
            'operation_id': operation_id,
            'provisioning_state': provisioning_state,
            'elapsed_minutes': 0,
            'alerts': []
        }

        # Calculate elapsed time
        started = datetime.fromisoformat(op['started_at'])
        elapsed = datetime.now() - started
        elapsed_minutes = elapsed.total_seconds() / 60
        result['elapsed_minutes'] = int(elapsed_minutes)

        # Check for completion
        if provisioning_state == 'Succeeded':
            op['status'] = OperationStatus.COMPLETED.value
            op['completed_at'] = datetime.now().isoformat()
            op['actual_duration_minutes'] = int(elapsed_minutes)

            # Update benchmarks
            self._update_benchmarks(op)

            result['status'] = 'completed'

        elif provisioning_state == 'Failed':
            op['status'] = OperationStatus.FAILED.value

            # Create alert (2% - requires human)
            alert = {
                'id': f"alert_{operation_id}",
                'operation_id': operation_id,
                'severity': 'critical',
                'message': f"Disk clone failed for {op['customer_name']}",
                'timestamp': datetime.now().isoformat(),
                'requires_human': True
            }
            data['alerts'].append(alert)
            result['alerts'].append(alert)

        else:
            # Check for timeout
            if elapsed_minutes > op['estimated_duration_minutes'] * 2:
                alert = {
                    'id': f"timeout_{operation_id}",
                    'operation_id': operation_id,
                    'severity': 'warning',
                    'message': f"Disk clone taking longer than expected ({int(elapsed_minutes)} min vs {op['estimated_duration_minutes']} estimated)",
                    'timestamp': datetime.now().isoformat()
                }
                # Only add if not already alerted
                existing = [a for a in op['alerts'] if a.get('id') == alert['id']]
                if not existing:
                    op['alerts'].append(alert)
                    data['alerts'].append(alert)
                    result['alerts'].append(alert)

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

        return result

    def _update_benchmarks(self, operation: Dict) -> None:
        """Update benchmarks from completed operation"""

        with open(self.operations_file, 'r') as f:
            data = json.load(f)

        benchmarks = data['benchmarks']
        sku = operation['metrics']['sku']
        size_gb = operation['metrics']['disk_size_gb']
        duration = operation['actual_duration_minutes']

        # Update SKU benchmarks
        if sku not in benchmarks['by_sku']:
            benchmarks['by_sku'][sku] = {
                'count': 0,
                'total_minutes': 0,
                'avg_minutes': 0,
                'total_size_gb': 0,
                'avg_size_gb': 0
            }

        sku_data = benchmarks['by_sku'][sku]
        sku_data['count'] += 1
        sku_data['total_minutes'] += duration
        sku_data['avg_minutes'] = sku_data['total_minutes'] / sku_data['count']
        sku_data['total_size_gb'] += size_gb
        sku_data['avg_size_gb'] = sku_data['total_size_gb'] / sku_data['count']

        # Update overall average
        total_ops = sum(s['count'] for s in benchmarks['by_sku'].values())
        total_time = sum(s['total_minutes'] for s in benchmarks['by_sku'].values())
        benchmarks['avg_duration_minutes'] = total_time / max(total_ops, 1)

        with open(self.operations_file, 'w') as f:
            json.dump(data, f, indent=2)

    def get_azure_cli_monitor_command(self, disk_name: str, resource_group: str) -> str:
        """Generate Azure CLI command to check disk status"""
        return f'az disk show --name {disk_name} --resource-group {resource_group} --query "provisioningState" -o tsv'


class PermissionValidationLoop:
    """
    FEEDBACK LOOP 3: Permission Validation

    Validates permissions after migration to:
    - Verify NTFS permissions transferred correctly
    - Test share access from different user contexts
    - Compare permissions before/after
    - Alert on permission discrepancies
    """

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.validation_file = data_dir / "permission_validations.json"
        self._ensure_file()

    def _ensure_file(self):
        if not self.validation_file.exists():
            with open(self.validation_file, 'w') as f:
                json.dump({
                    'validations': {},
                    'common_issues': {},
                    'success_rate': 0
                }, f)

    def create_validation(
        self,
        operation_id: str,
        customer_id: str,
        shares: List[Dict]
    ) -> str:
        """Create a permission validation task"""

        validation_id = f"perm_{operation_id}"

        validation = {
            'id': validation_id,
            'operation_id': operation_id,
            'customer_id': customer_id,
            'created_at': datetime.now().isoformat(),
            'status': 'pending',
            'shares': shares,
            'results': [],
            'passed': None
        }

        with open(self.validation_file, 'r') as f:
            data = json.load(f)

        data['validations'][validation_id] = validation

        with open(self.validation_file, 'w') as f:
            json.dump(data, f, indent=2)

        return validation_id

    def record_result(
        self,
        validation_id: str,
        share_name: str,
        test_type: str,
        passed: bool,
        details: str = None
    ) -> None:
        """Record a permission test result"""

        with open(self.validation_file, 'r') as f:
            data = json.load(f)

        if validation_id not in data['validations']:
            return

        result = {
            'share': share_name,
            'test': test_type,
            'passed': passed,
            'details': details,
            'timestamp': datetime.now().isoformat()
        }

        data['validations'][validation_id]['results'].append(result)

        # Track common issues
        if not passed and details:
            issue_key = f"{test_type}:{details[:50]}"
            if issue_key not in data['common_issues']:
                data['common_issues'][issue_key] = 0
            data['common_issues'][issue_key] += 1

        with open(self.validation_file, 'w') as f:
            json.dump(data, f, indent=2)

    def complete_validation(self, validation_id: str) -> Dict[str, Any]:
        """Complete validation and generate summary"""

        with open(self.validation_file, 'r') as f:
            data = json.load(f)

        if validation_id not in data['validations']:
            return {'error': 'Validation not found'}

        validation = data['validations'][validation_id]
        results = validation['results']

        # Calculate results
        total_tests = len(results)
        passed_tests = sum(1 for r in results if r['passed'])

        validation['status'] = 'completed'
        validation['completed_at'] = datetime.now().isoformat()
        validation['passed'] = passed_tests == total_tests
        validation['summary'] = {
            'total_tests': total_tests,
            'passed': passed_tests,
            'failed': total_tests - passed_tests,
            'pass_rate': passed_tests / max(total_tests, 1)
        }

        # Generate remediation for failures
        failures = [r for r in results if not r['passed']]
        if failures:
            validation['remediation_required'] = True
            validation['failed_items'] = failures

        with open(self.validation_file, 'w') as f:
            json.dump(data, f, indent=2)

        return validation

    def get_powershell_test_commands(self, share_path: str, test_user: str) -> List[str]:
        """Generate PowerShell commands for testing permissions"""
        return [
            f"# Test read access",
            f"Test-Path '{share_path}'",
            f"Get-ChildItem '{share_path}' -ErrorAction SilentlyContinue | Select-Object -First 1",
            f"",
            f"# Get current permissions",
            f"Get-Acl '{share_path}' | Format-List",
            f"",
            f"# Test write access (create temp file)",
            f"$testFile = Join-Path '{share_path}' 'permission_test.tmp'",
            f"'test' | Out-File $testFile -ErrorAction SilentlyContinue",
            f"if (Test-Path $testFile) {{ Remove-Item $testFile; 'Write access: OK' }} else {{ 'Write access: DENIED' }}"
        ]


class MigrationOrchestrator:
    """
    Master orchestrator for all Azure migration feedback loops

    Coordinates monitoring across all operation types and
    provides unified status and alerting
    """

    def __init__(self, data_dir: str = None):
        self.data_dir = Path(data_dir) if data_dir else Path(__file__).parent.parent / "feedback"
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self.robocopy_loop = RobocopyVerificationLoop(self.data_dir)
        self.disk_clone_loop = AzureDiskCloneLoop(self.data_dir)
        self.permission_loop = PermissionValidationLoop(self.data_dir)

    def start_dc_to_fs_migration(
        self,
        customer_id: str,
        customer_name: str,
        source_server: str,
        target_server: str,
        data_size_gb: float,
        shares: List[Dict]
    ) -> Dict[str, str]:
        """
        Start a complete DC to FS migration with all monitoring

        Returns operation IDs for tracking
        """

        operations = {}

        # Start robocopy monitoring
        robocopy_id = self.robocopy_loop.start_operation(
            customer_id=customer_id,
            customer_name=customer_name,
            source=source_server,
            destination=target_server,
            estimated_size_gb=data_size_gb
        )
        operations['robocopy'] = robocopy_id

        # Create permission validation (will run after robocopy)
        permission_id = self.permission_loop.create_validation(
            operation_id=robocopy_id,
            customer_id=customer_id,
            shares=shares
        )
        operations['permission_validation'] = permission_id

        return operations

    def start_azure_disk_clone(
        self,
        customer_id: str,
        customer_name: str,
        source_disk: str,
        target_disk: str,
        disk_size_gb: int,
        sku: str = 'Premium_LRS'
    ) -> str:
        """Start Azure disk clone with monitoring"""

        return self.disk_clone_loop.start_clone(
            customer_id=customer_id,
            customer_name=customer_name,
            source_disk=source_disk,
            target_disk=target_disk,
            disk_size_gb=disk_size_gb,
            sku=sku
        )

    def get_all_active_operations(self) -> List[Dict]:
        """Get all active operations across all loops"""

        active = []

        # Check robocopy operations
        robocopy_file = self.data_dir / "robocopy_operations.json"
        if robocopy_file.exists():
            with open(robocopy_file, 'r') as f:
                data = json.load(f)
            for op_id, op in data['operations'].items():
                if op['status'] in ['in_progress', 'requires_review']:
                    active.append({
                        'type': 'robocopy',
                        'id': op_id,
                        **op
                    })

        # Check disk clone operations
        clone_file = self.data_dir / "disk_clone_operations.json"
        if clone_file.exists():
            with open(clone_file, 'r') as f:
                data = json.load(f)
            for op_id, op in data['operations'].items():
                if op['status'] in ['in_progress', 'requires_review']:
                    active.append({
                        'type': 'disk_clone',
                        'id': op_id,
                        **op
                    })

        return active

    def get_all_pending_alerts(self) -> List[Dict]:
        """Get all unacknowledged alerts (2% requiring human attention)"""

        alerts = []
        alerts.extend(self.robocopy_loop.get_pending_alerts())

        # Add disk clone alerts
        clone_file = self.data_dir / "disk_clone_operations.json"
        if clone_file.exists():
            with open(clone_file, 'r') as f:
                data = json.load(f)
            alerts.extend([a for a in data.get('alerts', [])
                          if not a.get('acknowledged', False)])

        return alerts

    def get_migration_dashboard(self, customer_id: str = None) -> Dict[str, Any]:
        """Get unified migration dashboard"""

        dashboard = {
            'generated_at': datetime.now().isoformat(),
            'active_operations': self.get_all_active_operations(),
            'pending_alerts': self.get_all_pending_alerts(),
            'recent_completions': [],
            'benchmarks': {}
        }

        if customer_id:
            dashboard['active_operations'] = [
                op for op in dashboard['active_operations']
                if op.get('customer_id') == customer_id
            ]

        # Add benchmarks
        robocopy_file = self.data_dir / "robocopy_operations.json"
        if robocopy_file.exists():
            with open(robocopy_file, 'r') as f:
                data = json.load(f)
            dashboard['benchmarks']['robocopy'] = data.get('benchmarks', {})

        clone_file = self.data_dir / "disk_clone_operations.json"
        if clone_file.exists():
            with open(clone_file, 'r') as f:
                data = json.load(f)
            dashboard['benchmarks']['disk_clone'] = data.get('benchmarks', {})

        return dashboard
