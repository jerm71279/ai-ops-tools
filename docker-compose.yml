# =============================================================================
# OberaConnect AI Ops - Unified Docker Compose
# =============================================================================
#
# 5-Layer Architecture:
#   Layer 5: UI/Interface    - open-webui, n8n
#   Layer 4: Orchestration   - gateway (nginx)
#   Layer 3: Services        - data-processing, rag-engine, engineering-api, call-flow, agents
#   Layer 2: Persistence     - postgres, qdrant, chroma volumes
#   Layer 1: Models          - ollama (local LLMs)
#
# Usage:
#   docker compose up -d                                    # Core services only
#   docker compose --profile local-llm up -d                # + Ollama
#   docker compose --profile chat up -d                     # + Open WebUI
#   docker compose --profile local-llm --profile chat up -d # + Both
#   docker compose --profile ssl up -d                      # + SSL termination
#   docker compose --profile scan up -d                     # + Network scanner
#
# =============================================================================

services:
  # ===========================================================================
  # LAYER 1: MODELS
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Ollama - Local LLM Server (NVIDIA GPU)
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - oberaconnect-network
    profiles:
      - local-llm
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ===========================================================================
  # LAYER 2: PERSISTENCE
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # PostgreSQL - Relational Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-obera}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      - POSTGRES_DB=${POSTGRES_DB:-oberaconnect}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "127.0.0.1:5432:5432"
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-obera}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # ---------------------------------------------------------------------------
  # Qdrant - Vector Database
  # ---------------------------------------------------------------------------
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "127.0.0.1:6333:6333"
      - "127.0.0.1:6334:6334"
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__STORAGE__SNAPSHOTS_PATH=/qdrant/snapshots
      - QDRANT__SERVICE__API_KEY=${QDRANT_API_KEY:?QDRANT_API_KEY is required}
      - QDRANT__SERVICE__READ_ONLY_API_KEY=${QDRANT_READ_ONLY_API_KEY:-}
    volumes:
      - qdrant_storage:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 256M

  # ===========================================================================
  # LAYER 3: SERVICES (Secondbrain Microservices)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Data Processing Service
  # ---------------------------------------------------------------------------
  data-processing:
    build:
      context: ./core/Secondbrain
      dockerfile: docker/data-processing/Dockerfile
    container_name: sb-data-processing
    ports:
      - "8081:8080"
    environment:
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - ./core/Secondbrain/data:/app/data
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ---------------------------------------------------------------------------
  # RAG Engine Service
  # ---------------------------------------------------------------------------
  rag-engine:
    build:
      context: ./core/Secondbrain
      dockerfile: docker/rag-engine/Dockerfile
    container_name: sb-rag-engine
    ports:
      - "8082:8080"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - CHROMA_PERSIST_DIRECTORY=/app/chroma_db
      - OBSIDIAN_VAULT_PATH=/app/vault
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./core/Secondbrain/chroma_db:/app/chroma_db
      - /mnt/c/Users/JeremySmith/OneDrive - Obera Connect/MyVault:/app/vault:ro
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ---------------------------------------------------------------------------
  # Engineering API Service
  # ---------------------------------------------------------------------------
  engineering-api:
    build:
      context: ./core/Secondbrain
      dockerfile: docker/engineering-api/Dockerfile
    container_name: sb-engineering-api
    ports:
      - "8083:8080"
    environment:
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - SENDGRID_API_KEY=${SENDGRID_API_KEY:-}
    volumes:
      - ./core/Secondbrain/data:/app/data
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ---------------------------------------------------------------------------
  # Call Flow Service
  # ---------------------------------------------------------------------------
  call-flow:
    build:
      context: ./core/Secondbrain
      dockerfile: docker/call-flow/Dockerfile
    container_name: sb-call-flow
    ports:
      - "8084:8080"
    environment:
      - AZURE_TENANT_ID=${AZURE_TENANT_ID}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - ./core/Secondbrain/data/call_flows:/app/data/call_flows
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ---------------------------------------------------------------------------
  # AI Agents Service
  # ---------------------------------------------------------------------------
  agents:
    build:
      context: ./core/Secondbrain
      dockerfile: docker/agents/Dockerfile
    container_name: sb-agents
    ports:
      - "8085:8080"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./core/Secondbrain/data/agents:/app/data/agents
      - ./core/Secondbrain/data/ba_agent_data.json:/app/data/ba_agent_data.json
      - ./core/Secondbrain/vault:/app/vault
    restart: unless-stopped
    networks:
      - oberaconnect-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # LAYER 4: ORCHESTRATION
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # API Gateway (Nginx)
  # ---------------------------------------------------------------------------
  gateway:
    image: nginx:alpine
    container_name: sb-gateway
    ports:
      - "8080:80"
    volumes:
      - ./core/Secondbrain/docker/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      data-processing:
        condition: service_healthy
      rag-engine:
        condition: service_healthy
      engineering-api:
        condition: service_healthy
      call-flow:
        condition: service_healthy
      agents:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - oberaconnect-network

  # ===========================================================================
  # LAYER 5: UI / INTERFACE
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # n8n - Workflow Automation
  # ---------------------------------------------------------------------------
  n8n:
    image: docker.n8n.io/n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "127.0.0.1:5678:5678"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD:?N8N_BASIC_AUTH_PASSWORD is required}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:?N8N_ENCRYPTION_KEY is required}
      - WEBHOOK_URL=${WEBHOOK_URL:-https://localhost:5678}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - GENERIC_TIMEZONE=${TIMEZONE:-America/Chicago}
      - TZ=${TIMEZONE:-America/Chicago}
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168
      - EXECUTIONS_DATA_SAVE_ON_ERROR=all
      - EXECUTIONS_DATA_SAVE_ON_SUCCESS=all
      - EXECUTIONS_DATA_SAVE_ON_PROGRESS=false
      - EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS=true
      - N8N_PAYLOAD_SIZE_MAX=64
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY}
    volumes:
      - n8n_data:/home/node/.n8n
      - ./skills/n8n-secondbrain/workflows:/home/node/workflows
      - ./skills/n8n-secondbrain/backups:/home/node/backups
    networks:
      - oberaconnect-network
    depends_on:
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Open WebUI - Chat Interface
  # ---------------------------------------------------------------------------
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL:-}
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-changeme}
      - WEBUI_AUTH=false
    volumes:
      - open_webui_data:/app/backend/data
    restart: unless-stopped
    networks:
      - oberaconnect-network
    depends_on:
      - ollama
    profiles:
      - chat
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ---------------------------------------------------------------------------
  # Nginx SSL Proxy (optional)
  # ---------------------------------------------------------------------------
  nginx-ssl:
    image: nginx:alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./skills/n8n-secondbrain/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./skills/n8n-secondbrain/nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - oberaconnect-network
    depends_on:
      - n8n
      - gateway
    profiles:
      - ssl

  # ===========================================================================
  # OPTIONAL: Network Scanner
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Kali Nmap - Network Discovery
  # ---------------------------------------------------------------------------
  kali-nmap:
    build:
      context: ./projects/Nmap_Project
      dockerfile: Dockerfile
    container_name: kali-network-discovery
    network_mode: host
    privileged: true
    volumes:
      - ./projects/Nmap_Project/scans:/scans
    stdin_open: true
    tty: true
    cap_add:
      - NET_ADMIN
      - NET_RAW
    restart: unless-stopped
    profiles:
      - scan

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  oberaconnect-network:
    driver: bridge
    name: oberaconnect-network

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  # Layer 1: Models
  ollama_models:
    name: ollama_models

  # Layer 2: Persistence
  postgres_data:
    name: postgres_data
  qdrant_storage:
    name: qdrant_storage
    external: true
  qdrant_snapshots:
    name: qdrant_snapshots
    external: true

  # Layer 5: UI
  n8n_data:
    name: n8n_data
    external: true
  open_webui_data:
    name: open_webui_data
